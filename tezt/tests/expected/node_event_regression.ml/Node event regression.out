
./octez-node-event-regression
unexpected_receipts_layout,node.replay,error,"unexpected receipts layout for block {hash} - expected: {expected}, replay result: {replay_result}"
inconsistent_operation_receipt,node.replay,error,"inconsistent operation receipt at {operation_index}:\nexpected {expected_hash}: {expected}\nreplayed {result_hash}: {result}"
inconsistent_block_receipt,node.replay,error,"inconsistent block receipt - expected: {expected}, replay result: {replay_result}"
inconsistent_context_hash,node.replay,error,"inconsistent context hash - expected: {expected}, replay result: {replay_result}"
block_validation_end,node.replay,notice,"block validated in {duration}"
block_validation_start,node.replay,notice,"replaying block {alias}{hash} ({level})"
export_unspecified_hash,node.main,notice,"There is no block hash specified with the `--block` option. Using the last checkpoint as the default value"
cleaning_up_after_failure,node.main,error,"cleaning up directory \"{directory}\" after failure."
integrity_info,node.storage,notice,"running integrity check on inodes for block {block_hash} (level {block_level}) with context hash {context_hash}"
incorrect_history_mode,node.main,error,"The given history mode {given_history_mode} does not correspond to the stored history mode {stored_history_mode}. If you wish to force the switch, use the flag '--force-history-mode-switch'."
metrics_ended,node.main,error,"metrics server ended with error {stacktrace}"
bye,node.main,notice,"bye"
shutting_down_rpc_server,node.main,notice,"shutting down the RPC server"
shutting_down_node,node.main,notice,"shutting down the Tezos node"
node_is_ready,node.main,notice,"the Tezos node is now running"
starting_node,node.main,notice,"starting the Tezos node v{version} ({git_info})"
starting_metrics_server,node.main,notice,"starting metrics server on {host}:{port}"
starting_rpc_server,node.main,notice,"starting RPC server on {host}:{port} (acl = {acl_policy})"
disabled_config_validation,node.main,warning,"disabled node configuration validation"
disabled_listen_addr,node.main,notice,"disabled P2P server"
disabled_discovery_addr,node.main,notice,"disabled local peer discovery"
warn_no_check,node.snapshots,warning,"Warning: to speed up the import, the consistency of the imported data will not be fully checked. It is not recommended to use this option with a snapshot downloaded from an untrusted source"
validate_protocol_sources,node.snapshots,notice,"validating protocol {hash} against sources"
suggest_no_check,node.snapshots,notice,"Note: the import of a snapshot can be sped up using the '--no-check' option. Only use this option if you fully trust the snapshot source."
cleaning_after_failure,node.snapshots,notice,"cleaning up artifacts after failure"
import_succes,node.snapshots,notice,"successful import from file {filename}"
import_loading,node.snapshots,notice,"retrieving and validating data. This can take a while, please bear with us"
import_unspecified_hash,node.snapshots,notice,"you may consider using the --block <block_hash> argument to ensure that the block imported is the one you expected"
import_info,node.snapshots,notice,"importing data from snapshot {filename}: {header}"
cleaning_tmp_export_directory,node.snapshots,notice,"cleaning leftover export directory '{filename}'"
export_success,node.snapshots,notice,"successful export: {filename}"
export_info,node.snapshots,notice,"exporting a snapshot (v{version}) in {history_mode} mode, targeting block hash {block}"
reconstruct_block_success,node.reconstruction,debug,"the block {block_descr} was successfully reconstructed"
reconstruct_success,node.reconstruction,notice,"the storage was successfully reconstructed"
reconstruct_enum,node.reconstruction,notice,"enumerating all blocks to reconstruct"
reconstruct_resuming,node.reconstruction,notice,"resuming reconstruction from block {start_block} toward block {end_block}"
reconstruct_start_default,node.reconstruction,notice,"starting reconstruct from genesis toward block {block}"
shutdown_store,node.shutdown,info,"closing store"
shutdown_validator,node.shutdown,info,"shutting down the validator"
shutdown_ddb,node.shutdown,info,"shutting down the distributed database"
shutdown_p2p,node.shutdown,info,"shutting down the p2p layer"
context_already_consistent,node.storage_consistency,info,"no corruption detected while scanning the context."
corrupted_context_detected,node.storage_consistency,error,"context corruption detected"
store_successful_store,node.protocol_store,info,"protocol {protocol} successfully stored"
store_protocol_incorrect_hash,node.protocol_store,warning,"protocol {protocol} won't be stored: wrong hash"
store_protocol_missing_files,node.protocol_store,warning,"protocol {protocol} won't be stored: missing source files"
store_protocol_already_included,node.protocol_store,debug,"protocol {protocol} is already in store: nothing to do"
p2p-initialization,node,notice,"p2p initialization: {status}"
shutdown_chain_validator,node.validator,notice,"shutting down the chain validator {chain}"
shutdown_block_validator,node.validator,notice,"shutting down the block validator"
activate_chain,node.validator,notice,"activate chain {chain}"
started_for_validator-chain,validator.chain,info,"worker started for {name}"
started_validator-chain,validator.chain,info,"worker started"
crashed_validator-chain,validator.chain,error,"worker crashed [validator-chain]: {error}"
triggering_validator-chain,validator.chain,debug,"triggering shutting down"
terminate_validator-chain,validator.chain,info,"worker terminated [validator-chain]"
request_no_errors_validator-chain,validator.chain,debug,"{view} {request_status}"
request_validator-chain,validator.chain,debug,"{view} {request_status} {errors}"
started_for_prevalidator,prevalidator,info,"worker started for {name}"
started_prevalidator,prevalidator,info,"worker started"
crashed_prevalidator,prevalidator,error,"worker crashed [prevalidator]: {error}"
triggering_prevalidator,prevalidator,debug,"triggering shutting down"
terminate_prevalidator,prevalidator,info,"worker terminated [prevalidator]"
request_no_errors_prevalidator,prevalidator,debug,"{view} {request_status}"
request_prevalidator,prevalidator,debug,"{view} {request_status} {errors}"
operation_not_fetched,prevalidator,debug,"Operation {oph} was not fetched"
banned_operation_encountered,prevalidator,notice,"{origin}: banned {oph} encountered"
request_completed_debug,prevalidator,debug,"{view} {worker_status}"
request_completed_info,prevalidator,info,"{view} in {worker_status}"
operation_banned,prevalidator,notice,"operation {oph} banned"
operation_injected,prevalidator,notice,"operation {oph} injected "
operation_reclassified,prevalidator,debug,"operation {oph} reclassified"
operations_to_reclassify,prevalidator,debug,"{count} operations set to be reeclassified after the flush"
operation_included,prevalidator,debug,"operation {oph} included before being prevalidated"
fetching_operation,prevalidator,debug,"fetching operation {oph}"
processing_operations,prevalidator,debug,"processing operations"
unparsable_operation,prevalidator,debug,"unparsable operation {oph}"
invalid_mempool_filter_configuration,prevalidator,warning,"invalid mempool filter configuration"
request_failed,prevalidator,notice,"request {view} failed {worker_status}: {errors}"
started_for_validator-peer,validator.peer,info,"worker started for {name}"
started_validator-peer,validator.peer,info,"worker started"
crashed_validator-peer,validator.peer,error,"worker crashed [validator-peer]: {error}"
triggering_validator-peer,validator.peer,debug,"triggering shutting down"
terminate_validator-peer,validator.peer,info,"worker terminated [validator-peer]"
request_no_errors_validator-peer,validator.peer,debug,"{view} {request_status}"
request_validator-peer,validator.peer,debug,"{view} {request_status} {errors}"
insufficient_history,validator.peer,notice,"disconnected from peer {peer}: insufficient history"
peer_disconnection,validator.peer,notice,"peer {peer} disconnected"
request_error,validator.peer,notice,"request {view} failed ({status}): {error}"
request_completed,validator.peer,debug,"request {view} completed ({status})"
terminating_worker,validator.peer,debug,"terminating the validation worker for peer {peer} ({reason})"
processing_new_branch,validator.peer,debug,"processing new branch fron peer {peer}: {hash}"
processing_new_head,validator.peer,debug,"processing new head fron peer {peer}: {hash}"
no_new_head_from_peer,validator.peer,debug,"no new head from peer {peer} for {delay}"
ignoring_branch_without_common_ancestor,validator.peer,debug,"ignoring branch with head {hash} from {peer} (no common ancestor)"
ignoring_branch_with_invalid_locator,validator.peer,debug,"ignoring branch with head {hash} from {peer} (invalid locator)"
missing_new_head_predecessor,validator.peer,debug,"missing new head's predecessor {hash} from {peer}"
ignoring_prechecked_invalid_block,validator.peer,debug,"ignoring invalid block {hash} from {peer}"
ignoring_prechecked_block,validator.peer,debug,"ignoring prechecked head {hash} from {peer}"
ignoring_invalid_block,validator.peer,debug,"ignoring invalid block {hash} from {peer}"
ignoring_previously_validated_block,validator.peer,debug,"ignoring previously validated head {hash} from {peer}"
ignoring_head,validator.peer,debug,"ignoring head {hash} from peer {peer} with non-increasing fitness"
new_head_validation_end,validator.peer,debug,"new head validation from {peer} for head {hash} ended"
requesting_new_head_validation,validator.peer,debug,"requesting new head validation from {peer} for head {hash}"
fetching_operations_for_head,validator.peer,debug,"fetching operaitons from {peer} for head {hash}"
new_branch_validated,validator.peer,debug,"branch from {peer} validated with head {hash}"
validating_new_branch,validator.peer,debug,"validating new branch from peer {peer} (approx. {length} blocks)"
unexpected_error_while_fetching_headers,node.validator.bootstrap_pipeline,error,"unexpected error while fetching headers: {trace}"
locator_too_short,node.validator.bootstrap_pipeline,warning,"received a locator that is too short"
locator_contains_future_block,node.validator.bootstrap_pipeline,warning,"block locator {block_hash} from peer {peer_id} contains future blocks"
header_request_timeout,node.validator.bootstrap_pipeline,warning,"request for header {block_hash} from peer {peer_id} timed out"
step_too_short,node.validator.bootstrap_pipeline,warning,"invalid step from peer {peer_id} (too short)"
step_too_long,node.validator.bootstrap_pipeline,warning,"invalid step from peer {peer_id} (too long)"
request_operations_timeout,node.validator.bootstrap_pipeline,warning,"request for operations {block_hash}:{operations_index_tag} from peer {peer_id} timed out"
validated_block,node.validator.bootstrap_pipeline,debug,"validated block {block_hash} from peer {peer_id}"
requesting_validation,node.validator.bootstrap_pipeline,debug,"requesting validation for block {block_hash} from peer {peer_id}"
fetched_operations,node.validator.bootstrap_pipeline,debug,"fetched operations of block {block_hash} from peer {peer_id}"
fetching_operations,node.validator.bootstrap_pipeline,debug,"fetching operations of block {block_hash} from peer {peer_id}"
fetching_all_steps_from_peer,node.validator.bootstrap_pipeline,debug,"fetched all steps from peer {peer_id}"
fetching_block_header_from_peer,node.validator.bootstrap_pipeline,debug,"fetched header {block} from {peer_id} {block_fetched}/{step_length}"
fetching_step_from_peer,node.validator.bootstrap_pipeline,info,"fetching step {step_number}/{number_of_steps} (step length {step_length}) from {block} to {predecessor} from peer {peer_id}"
still_fetching_block_header_from_peer,node.validator.bootstrap_pipeline,info,"still fetching headers from peer {peer_id}: {block_fetched}/{step_length}"
fetching_locator,node.validator.bootstrap_pipeline,notice,"fetching branch of {locator_length} blocks from peer {peer_id}"
bootstrap_active_peers_heads_time,validator.chain,debug,"bootstrap peers: active {active} needed {needed}"
bootstrap_active_peers,validator.chain,debug,"bootstrap peers: active {active} needed {needed}"
block_info,validator.chain,info,"treated block has timestamp {timestamp} with fitness {fitness}"
bootstrap_time_remaining,validator.chain,notice,"synchronizing: current head is {timediff} old (level: {level})"
head_increment,validator.chain,notice,"head is now {view} ({level})"
branch_switch,validator.chain,notice,"switch branch to {view} ({level})"
ignore_head,validator.chain,notice,"current head is better than {view} (level {level}), we do not switch"
disconnection,validator.chain,info,"disconnection of {peer_id}"
connection,validator.chain,info,"connection of {peer_id}"
notify_branch,validator.chain,info,"branch up to {head_hash} from {peer_id} processed"
notify_head,validator.chain,debug,"head {block_hash} from {peer_id} processed"
request_failure,validator.chain,notice,"chain validator request {view} failed ({worker_status}): {errors}"
could_not_switch_testchain,validator.chain,error,"error while switching testchina: {trace}"
synchronisation_status,validator.chain,notice,"synchronisation status: {status}"
bootstrapped,validator.chain,notice,"chain is bootstrapped"
loading_protocol,validator.chain,notice,"loading non-embedded protocol {protocol} from disk"
prevalidator_instantiation_failure,validator.chain,error,"failed to instantiate the prevalidator: {trace}"
prevalidator_reinstantiation_failure,validator.chain,error,"failed to reinstantiate prevalidator error {trace}"
prevalidator_filter_not_found,validator.chain,warning,"no prevalidator filter found for protocol {protocol_hash}"
updated_to_checkpoint,validator.chain,notice,"updated to checkpoint {block_hash} (running in mode {history_mode})"
predecessor_less_block,prevalidator_classification,warning,"Observing that a parent of block {blk_h} has no predecessor"
started_for_validator-block,validator.block,info,"worker started for {name}"
started_validator-block,validator.block,info,"worker started"
crashed_validator-block,validator.block,error,"worker crashed [validator-block]: {error}"
triggering_validator-block,validator.block,debug,"triggering shutting down"
terminate_validator-block,validator.block,info,"worker terminated [validator-block]"
request_no_errors_validator-block,validator.block,debug,"{view} {request_status}"
request_validator-block,validator.block,debug,"{view} {request_status} {errors}"
fetching_protocol,node.validator,notice,"fetching protocol {hash}"
pushing_protocol_validation,node.validator,debug,"pushing validation request for protocol {hash}"
previously_validated_protocol,node.validator,debug,"protocol {hash} already validated, ignoring"
unexpected_worker_error,node.validator,notice,"unexpected worker error: {trace}"
validator_terminated,node.validator,notice,"validator terminated"
requester_worker_timeout__protocol,node.requester.scheduler,debug,"requester worker timout"
requester_worker_terminated__protocol,node.requester.scheduler,debug,"requester worker terminating"
requester_requested__protocol,node.requester.scheduler,debug,"requested {name} from {peer}"
requester_notify_duplicate__protocol,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_unrequested__protocol,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_invalid__protocol,node.requester.scheduler,debug,"received invalid {name} from {peer}"
requester_notify_cancelled__protocol,node.requester.scheduler,debug,"cancelled {name}"
requester_notify_received__protocol,node.requester.scheduler,debug,"received {name} from {peer}"
requester_registering_request_added__protocol,node.requester.scheduler,debug,"registering request {name} from {peer} -> added"
requester_registering_request_replaced__protocol,node.requester.scheduler,debug,"registering request {name} from {peer} -> replaced"
requester_registering_request__protocol,node.requester.scheduler,debug,"registering request {name} from {peer}"
requester_notify_push_unrequested__protocol,node.requester.scheduler,debug,"push received unrequested {name} from {peer}"
requester_notify_push_duplicate__protocol,node.requester.scheduler,debug,"push received duplicate {name} from {peer}"
requester_notify_push_invalid__protocol,node.requester.scheduler,debug,"push received invalid {name} from {peer}"
requester_notify_push_cancellation__protocol,node.requester.scheduler,debug,"push cancellation {name}"
requester_notify_push__protocol,node.requester.scheduler,debug,"push received {name} from {peer}"
requester_worker_timeout__operations,node.requester.scheduler,debug,"requester worker timout"
requester_worker_terminated__operations,node.requester.scheduler,debug,"requester worker terminating"
requester_requested__operations,node.requester.scheduler,debug,"requested {name} from {peer}"
requester_notify_duplicate__operations,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_unrequested__operations,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_invalid__operations,node.requester.scheduler,debug,"received invalid {name} from {peer}"
requester_notify_cancelled__operations,node.requester.scheduler,debug,"cancelled {name}"
requester_notify_received__operations,node.requester.scheduler,debug,"received {name} from {peer}"
requester_registering_request_added__operations,node.requester.scheduler,debug,"registering request {name} from {peer} -> added"
requester_registering_request_replaced__operations,node.requester.scheduler,debug,"registering request {name} from {peer} -> replaced"
requester_registering_request__operations,node.requester.scheduler,debug,"registering request {name} from {peer}"
requester_notify_push_unrequested__operations,node.requester.scheduler,debug,"push received unrequested {name} from {peer}"
requester_notify_push_duplicate__operations,node.requester.scheduler,debug,"push received duplicate {name} from {peer}"
requester_notify_push_invalid__operations,node.requester.scheduler,debug,"push received invalid {name} from {peer}"
requester_notify_push_cancellation__operations,node.requester.scheduler,debug,"push cancellation {name}"
requester_notify_push__operations,node.requester.scheduler,debug,"push received {name} from {peer}"
requester_worker_timeout__block_header,node.requester.scheduler,debug,"requester worker timout"
requester_worker_terminated__block_header,node.requester.scheduler,debug,"requester worker terminating"
requester_requested__block_header,node.requester.scheduler,debug,"requested {name} from {peer}"
requester_notify_duplicate__block_header,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_unrequested__block_header,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_invalid__block_header,node.requester.scheduler,debug,"received invalid {name} from {peer}"
requester_notify_cancelled__block_header,node.requester.scheduler,debug,"cancelled {name}"
requester_notify_received__block_header,node.requester.scheduler,debug,"received {name} from {peer}"
requester_registering_request_added__block_header,node.requester.scheduler,debug,"registering request {name} from {peer} -> added"
requester_registering_request_replaced__block_header,node.requester.scheduler,debug,"registering request {name} from {peer} -> replaced"
requester_registering_request__block_header,node.requester.scheduler,debug,"registering request {name} from {peer}"
requester_notify_push_unrequested__block_header,node.requester.scheduler,debug,"push received unrequested {name} from {peer}"
requester_notify_push_duplicate__block_header,node.requester.scheduler,debug,"push received duplicate {name} from {peer}"
requester_notify_push_invalid__block_header,node.requester.scheduler,debug,"push received invalid {name} from {peer}"
requester_notify_push_cancellation__block_header,node.requester.scheduler,debug,"push cancellation {name}"
requester_notify_push__block_header,node.requester.scheduler,debug,"push received {name} from {peer}"
requester_worker_timeout__operation,node.requester.scheduler,debug,"requester worker timout"
requester_worker_terminated__operation,node.requester.scheduler,debug,"requester worker terminating"
requester_requested__operation,node.requester.scheduler,debug,"requested {name} from {peer}"
requester_notify_duplicate__operation,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_unrequested__operation,node.requester.scheduler,debug,"received unrequested {name} from {peer}"
requester_notify_invalid__operation,node.requester.scheduler,debug,"received invalid {name} from {peer}"
requester_notify_cancelled__operation,node.requester.scheduler,debug,"cancelled {name}"
requester_notify_received__operation,node.requester.scheduler,debug,"received {name} from {peer}"
requester_registering_request_added__operation,node.requester.scheduler,debug,"registering request {name} from {peer} -> added"
requester_registering_request_replaced__operation,node.requester.scheduler,debug,"registering request {name} from {peer} -> replaced"
requester_registering_request__operation,node.requester.scheduler,debug,"registering request {name} from {peer}"
requester_notify_push_unrequested__operation,node.requester.scheduler,debug,"push received unrequested {name} from {peer}"
requester_notify_push_duplicate__operation,node.requester.scheduler,debug,"push received duplicate {name} from {peer}"
requester_notify_push_invalid__operation,node.requester.scheduler,debug,"push received invalid {name} from {peer}"
requester_notify_push_cancellation__operation,node.requester.scheduler,debug,"push cancellation {name}"
requester_notify_push__operation,node.requester.scheduler,debug,"push received {name} from {peer}"
received_future_block,node.distributed_db.p2p_reader,notice,"received future block {block_hash} from peer {peer_id}"
read_message,node.distributed_db.p2p_reader,debug,"read message from peer {peer_id}: {message}"
shutting_down_requester,node.distributed_db.requester,notice,"shutting down requester"
p2p_reader_shutdow_failed,node.distributed_db,warning,"p2p_reader of {peer} failed to shut down with {exn}"
multiple_p2p_reader,node.distributed_db,warning,"multiple p2p_reader for {peer}, a connection may be stuck"
proc_request_result,external_block_validator,debug,"completion of {request_result} in {timespan}"
proc_request,external_block_validator,debug,"request for {request}"
cannot_start_process,external_block_validator,info,"cannot start validation process: the node is shutting down"
unresponsive_validator,external_block_validator,notice,"force quitting the block validation process as it seems to be unresponsive"
cannot_close,external_block_validator,info,"cannot close the block validation process: connection failed"
proc_validator_started,external_block_validator,notice,"block validator process started with pid {pid}"
proc_exited_normally,external_block_validator,notice,"process terminated normally"
proc_status,external_block_validator,error,"{status_msg}"
proc_close,external_block_validator,notice,"shutting down external validation"
proc_initialized,external_block_validator,notice,"external validation initialized"
seq_validation_success,sequential_block_validator,debug,"block {block} successfully validated in {timespan}"
seq_validation_request,sequential_block_validator,debug,"requesting validation of {block} for chain {chain}"
seq_close,sequential_block_validator,notice,"shutting down internal validation"
seq_initialized,sequential_block_validator,notice,"internal validation initialized"
could_not_find_context,validator.block,debug,"could not find context for block {hash}"
prechecking_block,validator.block,debug,"prechecking block {hash}"
prechecked_block,validator.block,info,"prechecked block {hash}"
precheck_failure,validator.block,notice,"precheck of block {block} failed, {worker_status}: {errors}"
validation_failure_after_precheck,validator.block,notice,"validation of block {block} failed but precheck succeeded, {worker_status}: {errors}"
preapplication_failed,validator.block,notice,"pre-application of block at level {level} failed ({worker_status}): {errors}"
preapplication_success,validator.block,notice,"block at level {level} successfully pre-applied in {worker_status}"
validating_block,validator.block,debug,"validating block {hash}"
previously_validated,validator.block,debug,"previously validated block {hash} (after pipe)"
validation_failed,validator.block,notice,"validation of block {block} failed ({worker_status}): {errors}"
validation_success,validator.block,info,"block {block} validated in {worker_status}"
broadcast,p2p,debug,"message broadcast"
trysending_message_error,p2p,debug,"error trysending message to {peer}: {error}"
message_trysent,p2p,debug,"message trysent to {peer}"
sending_message_error,p2p,debug,"error sending message to {peer}: {error}"
message_to_send,p2p,debug,"message sent to {peer}"
shutdown_scheduler,p2p,notice,"shutting down the p2p scheduler..."
shutdown_connection_handler,p2p,notice,"shutting down the p2p connection handler..."
shutdown_connection_pool,p2p,notice,"shutting down the p2p connection pool..."
shutdown_maintenance_worker,p2p,notice,"shutting down the p2p's network maintenance worker..."
shutdown_welcome_worker,p2p,notice,"shutting down the p2p's welcome worker..."
message_read_error,p2p,debug,"error reading message from {peer}"
message_read,p2p,debug,"message read from {peer}"
activate_network,p2p,info,"activate id {peer}"
activate_layer,p2p,info,"activate P2P layer"
maintenance_disabled,p2p,warning,"the maintenance is disabled, this should be used for testing purposes only"
broadcast_error,p2p.discovery,debug,"Error broadcasting a discovery request"
broadcast_message,p2p.discovery,debug,"Broadcasting discovery message"
unexpected_exit,p2p.discovery,error,"Answer worker exited unexpectedly"
unexpected_error,p2p.discovery,error,"unexpected error in {worker} worker: {error}"
register_new,p2p.discovery,notice,"registering new point {point}"
parse_error,p2p.discovery,debug,"failed to parse ({address})"
message_received,p2p.discovery,debug,"received discovery message"
create_socket_error,p2p.discovery,debug,"error creating a socket"
save_error_peers,p2p.pool,error,"failed to save peers file: {error}"
save_metadata,p2p.pool,info,"saving metadata in {file}"
parse_error_peers,p2p.pool,error,"failed to parse peers file: {error}"
create_pool,p2p.pool,debug,"create pool: known points {point_list}"
get_points,p2p.pool,debug,"getting points from {medium} of {source}: {point_list}"
shutdown_io_scheduler,p2p.io-scheduler,info,"shutdown scheduler"
shutdown_connection,p2p.io-scheduler,info,"shutdown {name}"
close_connection,p2p.io-scheduler,debug,"close {connection_id}"
close_connection_error,p2p.io-scheduler,warning,"close {connection_id} failed with {error}"
register_connection,p2p.io-scheduler,debug,"register_connection {connection_id}"
create_connection,p2p.io-scheduler,debug,"create"
reset_quota,p2p.io-scheduler,debug,"reset quota"
update_quota,p2p.io-scheduler,debug,"update quota {name}"
create_connection_scheduler,p2p.io-scheduler,debug,"create connection ({connection_id},{name})"
handle_connection,p2p.io-scheduler,debug,"handle {len} ({connection_id},{name})"
scheduler_wait,p2p.io-scheduler,debug,"wait ({name})"
scheduler_wait_quota,p2p.io-scheduler,debug,"wait_quota ({name})"
unexpected_error_scheduler,p2p.io-scheduler,error,"unexpected error in connection ({direction}: {connection_id},{name}): {error}"
connection_closed_scheduler,p2p.io-scheduler,debug,"connection closed {direction} ({connection_id},{name})"
socket_write_error,p2p.socket,error,"unexpected error when writing to {peer}: {error}"
socket_write,p2p.socket,debug,"writing {bytes} to {peer}"
socket_read_error,p2p.socket,debug,"[read message] incremental decoding error"
socket_read,p2p.socket,debug,"reading {bytes} bytes from {peer}"
connection_closed,p2p.socket,debug,"connection closed to {peer}"
sending_authentication,p2p.socket,debug,"sending authentication to {point}"
nack_point_no_point,p2p.socket,debug,"nack point {point} (no point list due to p2p version)"
nack_point_with_list,p2p.socket,debug,"nack point {point} with point list {points}"
incoming_connection_error,p2p.welcome,error,"cannot accept incoming connections"
unexpected_error_closing_socket,p2p.welcome,error,"unexpected error while closing socket: {error}"
unexpected_error_welcome,p2p.welcome,error,"unexpected error: {error}"
incoming_error,p2p.welcome,debug,"incoming connection failed with {error}. Ignoring"
too_many_connections_maintenance,p2p.maintenance,debug,"too many connections (will kill {connections})"
too_few_connections_maintenance,p2p.maintenance,notice,"too few connections ({connections})"
maintenance_ended,p2p.maintenance,info,"maintenance step ended after {duration}"
maintenance_started,p2p.maintenance,info,"maintenance step started (triggered by:{motive})"
accept,p2p.fd,debug,"cnx:{connection_id}:accept {socket}"
connect,p2p.fd,debug,"cnx:{connection_id}:connect {socket}"
written_fd,p2p.fd,debug,"cnx:{connection_id}:written {nwrit} ({nwrit_total})"
read_fd,p2p.fd,debug,"cnx:{connection_id}:read {nread} ({nread_total})"
try_write,p2p.fd,debug,"cnx:{connection_id}:try write {length}"
try_read,p2p.fd,debug,"cnx:{connection_id}:try read {length}"
close_fd,p2p.fd,debug,"cnx:{connection_id}:close fd (stats : {nread}/{nwrit})"
create_fd,p2p.fd,debug,"cnx:{connection_id}:create fd"
advertise_received,p2p.conn,debug,"advertise message received from {emitter}"
bootstrap_received,p2p.conn,debug,"bootstrap message received from {emitter}"
disconnect,p2p.conn,debug,"{peer} has been explicitly closed"
bytes_popped_from_queue,p2p.conn,debug,"{bytes} bytes message popped from queue {peer}"
swap_request_received,p2p.conn,info,"swap request received from {emitter}"
swap_ack_received,p2p.conn,info,"swap ack received from {emitter}"
unexpected_error_answerer,p2p.conn,error,"answerer unexpected error: {errors}"
peer_discovery_disabled,p2p.conn,warning,"request for new peers interrupted because peer discovery disabled"
trigger_maintenance_too_few_connections,p2p.connect_handler,debug,"Too few connections : trigger maintenance (active_connections={active_connections} / min_connections={min_connections})"
trigger_maintenance_too_many_connections,p2p.connect_handler,debug,"Too many connections : trigger maintenance (active_connections={active_connections} / max_connections={max_connections})"
new_connection,p2p.connect_handler,info,"new connection to {addr}:{port}#{peer}"
authenticate_reject_protocol_mismatch,p2p.connect_handler,debug,"no common protocol with {peer}"
connect_close_error,p2p.connect_handler,debug,"connection error while closing for point {point}: {errors}"
connect_error,p2p.connect_handler,debug,"connection error for point {point}, disconnecting : {errors}"
connect_status,p2p.connect_handler,debug,"connection status for {point}: {state}"
connection_error,p2p.connect_handler,debug,"connection to {point} rejected by peer : {errors}"
connection_rejected_by_peers,p2p.connect_handler,debug,"connection to {point} rejected by peer {peer}. Reason {reason}. Peer list received: {points}"
authentication_error,p2p.connect_handler,debug,"authentication error for {point}: {errors}"
authenticate_status_peer_id_incorrect,p2p.connect_handler,warning,"authenticate failed: {point} {type}. Expected '{expected_peer_id}', got '{peer_id}'"
authenticate_status_peer_id_correct,p2p.connect_handler,notice,"expected peer id {peer} for this point {point}"
authenticate_status,p2p.connect_handler,debug,"authentication status for point {point} {type} -> {peer}"
authenticate,p2p.connect_handler,debug,"authentication for point {point}. direction:{direction} -> {state}"
authenticate_start,p2p.connect_handler,debug,"start authentication for point {point} ({direction})"
peer_rejected,p2p.connect_handler,notice,"[private node] incoming connection from untrusted peer rejected"
disconnected,p2p.connect_handler,debug,"disconnected: {peer} ({point})"
no_swap_candidate,p2p.protocol,info,"no swap candidate for {peer}"
swap_request_ignored,p2p.protocol,info,"swap request ignored from {peer}"
swap_failed,p2p.protocol,info,"swap to {point} failed: {trace}"
swap_interrupted,p2p.protocol,debug,"swap to {point} was interrupted: {trace}"
swap_succeeded,p2p.protocol,info,"swap to {point} succeeded"
advertise_sending_failed,p2p.protocol,warning,"sending advertise to {peer} failed: {trace}"
private_node_request,p2p.protocol,warning,"private peer ({peer}) asked other peer's addresses"
private_node_swap_ack,p2p.protocol,warning,"received swap ack from private peer {peer}"
private_node_swap_request,p2p.protocol,warning,"received swap requests from private peer {peer}"
private_node_peers_request,p2p.protocol,warning,"received requests for peers addresses from private peer {peer}"
private_node_new_peers,p2p.protocol,warning,"received new peers addresses from private peer {peer}"
identity_generated,node.identity,notice,"identity file generated"
generating_identity,node.identity,notice,"generating an identity file"
read_identity,node.identity,notice,"read identity file"
enable_testchain_is_deprecated_in_configuration_file,node.config.validation,warning,"warning: The option `p2p.enable_testchain` is deprecated."
target_number_of_known_points_greater_than_maximum_conn,node.config.validation,error,"error: the target number of known point ids ({target}) found in field 'p2p.limits.max_known_points' is lower than the maximum number of connections ({maximum}) found in 'p2p.limits.max-connections'."
target_number_of_known_points_greater_than_maximum,node.config.validation,error,"error: in field 'p2p.limits.max_known_points', the target number of known point ids ({target}) is greater than the maximum number of known points ids ({maximum})."
target_number_of_known_peers_greater_than_maximum_conn,node.config.validation,error,"error: the target number of known peer ids ({target}) in field 'p2p.limits.max_known_peer_ids', is lower than the maximum number of connections ({maximum}) found in field 'p2p.limits.max-connections'."
target_number_of_known_peers_greater_than_maximum,node.config.validation,error,"error: in field 'p2p.limits.max_known_peer_ids', the target number of known peer ids ({target}) is greater than the maximum number of known peers ids ({maximum})."
expected_connections_greater_than_maximum,node.config.validation,error,"error: the expected number of connections found in field 'p2p.limits.expected-connections' ({expected}) is greater than the maximum number of connections found in field 'p2p.limits.max-connections' ({maximum})."
minimum_connections_greater_than_expected,node.config.validation,error,"error: the minimum number of connections found in field 'p2p.limits.min-connections' ({minimum}) is greater than the expected number of connections found in field 'p2p.limits.expected-connections' ({expected})."
cannot_resolve_bootstrap_peer_addr,node.config.validation,warning,"warning: failed to resolve the bootstrap peer address '{addr}' in field '{field}', the node will not use this bootstrap peer"
cannot_resolve_addr,node.config.validation,warning,"warning: failed to resolve address '{addr}' in field '{field}'."
cannot_parse_addr,node.config.validation,error,"error: failed to parse address '{addr}' in field '{field}': {why}."
invalid_pow,node.config.validation,error,"error: the expected proof-of-work must be between 0 and 256 (inclusive), but found the value {proof-of-work} in field 'p2p.expected-proof-of-work'."
config_validation_warning,node.config.validation,warning,"found the following warning(s) while validating the node configuration."
config_validation_error,node.config.validation,error,"found the following error(s) while validating the node configuration."
config_validation_success,node.config.validation,notice,"the node configuration has been successfully validated."
config_validation_disabled,node.config.validation,notice,"the node configuration validation is disabled."
overriding_config_file_arg,node.main,warning,"the data directory from the --config-file argument was overridden by the given --data-dir path: {path}"
disable_mempool_precheck_is_deprecated,node.main,warning,"The command-line option `--disable-mempool-precheck` is deprecated and has no effects."
enable_testchain_is_deprecated,node.main,warning,"The command-line option `--enable-testchain` is deprecated."
disabled_bootstrap_peers,node.main,info,"disabled bootstrap peers"
all_rpc_allowed,node.main,error,"FULL access to RPC enabled; this is very risky."
cannot_convert_to_ipv4,node.main,warning,"failed to convert {addr} to an ipv4 address"
upgrade_status,node.data_version,notice,"current version: {current_version}, available version: {available_version}"
aborting_upgrade,node.data_version,notice,"failed to upgrade storage"
update_success,node.data_version,notice,"the node data dir is now up-to-date"
finished_upgrading_node,node.data_version,notice,"the node's data directory was automatically upgraded from {old_version} to {new_version} and is now up-to-date"
upgrading_node,node.data_version,notice,"upgrading data directory from {old_version} to {new_version}"
dir_is_up_to_date,node.data_version,notice,"node data dir is up-to-date"
upgrade_store_started,node.store,notice,"upgrading the store"
upgrade_store_failed,node.store,error,"store upgrade failed, cleaning up temporary files"
notify_merge_error,node.store,error,"store merge has failed, restart the node to restore the consistency: {errs}"
merge_error,node.store,error,"merge from {start} to {end} failed: {message}"
missing_metadata,node.store,warning,"the storage is missing some metadata for cycle {start_level}-{end_level}. Please consider restoring a consistent storage"
restore_inferred_history_mode,node.store,notice,"history mode was successfully restored to {history_mode}. Warning: this history mode may differ from the one preceding the restore procedure and you may need to restart the node to explicitly force the history mode switch"
restore_history_mode,node.store,notice,"history mode was successfully restored to {history_mode}, based on the configuration file or command line argument"
update_protocol_table,node.store,notice,"the protocol table was updated: protocol {proto_hash} (level {proto_level}) was activated on block {block_hash} (level {block_level})"
restore_protocol_activation,node.store,notice,"protocol {protocol_level} ({protocol_hash}) was successfully restored"
restore_protocols_table,node.store,notice,"restoring protocols table"
recovering_merge,node.store,notice,"recovering from an interrupted store merge"
store_was_fixed,node.store,notice,"the store was successfully fixed!"
fix_caboose,node.store,notice,"updating caboose (previously {prev}) with the lowest block found in the store: {new}"
fix_savepoint,node.store,notice,"updating savepoint (previously {prev}) with the lowest block with metadata found in the store: {new}"
fix_checkpoint,node.store,notice,"updating checkpoint (previously {prev}) with: {new}"
fix_cementing_highwatermark,node.store,notice,"updating cementing highwatermark (previously {prev}) with: {new}"
fix_head,node.store,notice,"updating head (previously {prev}) with the fittest block present in the store: {new}"
fix_floating_stores,node.store,notice,"the consistency of the floating stores was restored"
fix_store,node.store,notice,"attempting to restore the store's consistency..."
inconsistent_store,node.store,notice,"the store is in an inconsistent state: {errs}"
switch_history_mode,node.store,notice,"history mode successfully switched from {old} to {new}"
try_waiting_for_merge_termination,node.store,notice,"try waiting for the store's merge completion"
gc_is_not_allowed,node.store,warning,"garbage collection is not fully enabled on this data directory: context cannot be garbage collected. Please read the documentation or import a snapshot to enable it"
start_context_split,node.store,info,"splitting context into a new chunk at level {level}"
start_context_gc,node.store,info,"removing old contexts below block {block}"
end_merging_stores,node.store,notice,"store was successfully merged in {time}"
start_merging_stores,node.store,notice,"merging store up to block level {lafl}"
fork_testchain,node.store,notice,"the test chain {chain_id} for protocol {protocol_hash} with genesis block hash {genesis_hash} was initialized from {fork_block} and is now registered in the store"
error_while_reading_cemented_metadata,node.store,debug,"unexpected error while reading cemented metadata: {exc}"
store_is_consistent,node.store,debug,"the store is consistent"
start_retreiving_cycles,node.store,info,"retrieving cycles from floating store"
start_retreiving_predecessors,node.store,info,"retrieving predecessors from floating store"
start_merge_finalizer,node.store,info,"triggering merge finalizer"
start_store_garbage_collection,node.store,info,"garbage-collecting the cemented store"
end_merging_thread,node.store,info,"merging thread ended"
start_merging_thread,node.store,info,"running merging thread"
start_cementing_blocks_metadata,node.store,info,"cementing blocks metadata"
start_cementing_blocks,node.store,info,"cementing blocks"
start_updating_floating_stores,node.store,info,"updating floating stores"
store_validated_block,node.store,info,"validated block {block} was stored"
store_block,node.store,info,"block {block} was stored"
set_caboose,node.store,info,"the caboose was updated to {new_caboose}"
set_savepoint,node.store,info,"the savepoint was updated to {new_savepoint}"
set_target,node.store,debug,"the target was updated to {new_target}"
set_checkpoint,node.store,info,"checkpoint updated to {new_checkpoint}"
set_head,node.store,info,"{block} set as new head"
termination_request,external_validator,info,"validator terminated"
context_split_request,external_validator,info,"spliting context"
context_gc_request,external_validator,info,"garbage collecting context below {context_hash}"
fork_testchain_request,external_validator,info,"forking test chain at block {block}"
initialization_request,external_validator,info,"initializing validator's environment"
commit_genesis_request,external_validator,info,"committing genesis block {genesis}"
precheck_request,external_validator,info,"prechecking block {hash}"
validation_request,external_validator,info,"validating block {block}"
dynload_protocol,external_validator,info,"dynamic loading of protocol {protocol}"
terminated_request,external_validator,info,"validator terminated"
initialized,external_validator,info,"validator initialized and listening"
block_validation_inconsistent_cache,block.validation,warning,"applied block {hash} with an inconsistent cache: reloading cache"
internal_error,protocol_updater,error,"internal error while compiling {protocol}"
dynlink_error_static,protocol_updater,error,"can't load plugin either because the binary is statically linked or because there was an error in its compilation: {plugin} ({reason})"
dynlink_error,protocol_updater,error,"can't load plugin: {plugin} ({reason})"
compilation_error,protocol_updater,error,"compilation error (logs in file: {filename})"
compilation_interrupted,protocol_updater,error,"compilation interrupted (see logs in: {filename})"
compiler_exit_error,protocol_updater,error,"error: {error}"
node_uninitialized,protocol_updater,error,"node not initialized"
stop_loading_cache_lazily,protocol_cache,debug,"stop loading cache lazily"
start_loading_cache_lazily,protocol_cache,debug,"start loading cache lazily"
stop_loading_cache,protocol_cache,info,"stop loading cache now"
start_loading_cache,protocol_cache,info,"start loading cache now"
gc_launch_failure,node.context.disk,warning,"context garbage collection launch failed: {error}"
gc_failure,node.context.disk,warning,"context garbage collection failed: {error}"
split_context,node.context.disk,debug,"splitting context into a new chunk"
ending_gc,node.context.disk,info,"context garbage collection finished in {duration} (finalised in {finalisation})"
starting_gc,node.context.disk,info,"starting context garbage collection for commit {context_hash}"
init_context,node.context.disk,info,"initializing context (readonly: {readonly}, index_log_size: {index_log_size}, lru_size: {lru_size})"
logging_failure,node.protocol,error,"Failure to log a protocol message: {exc}"
fatal_from_protocol,node.protocol,fatal,"{message}"
error_from_protocol,node.protocol,error,"{message}"
warning_from_protocol,node.protocol,warning,"{message}"
notice_from_protocol,node.protocol,notice,"{message}"
info_from_protocol,node.protocol,info,"{message}"
debug_from_protocol,node.protocol,debug,"{message}"
destroy_state,node.state,debug,"destroy {chain_id}"
push_block,node.state,debug,"push_block {block_hash}"
pop_block,node.state,debug,"pop_block {block_hash}"
missing_pruned_contents,node.state,error,"cannot find pruned contents of block {block_hash}"
using_preapply_result,validation,info,"using pre-application result for block {block_hash} application"
new_protocol_initialisation,validation,notice,"initializing protocol {proto_hash}..."
config_no_points_found,config,warning,"The DNS lookup of {string} returns 0 point."
config_peer_id_unused,config,warning,"While parsing {string} a peer id was provided but will not be used."
lwt-worker_failed,,error,"Worker failed event"
lwt-worker_ended,,debug,"Worker ended event"
lwt-worker_started,,debug,"Worker started event"
debug-event,,debug,"Generic event for semi-structured debug information."
